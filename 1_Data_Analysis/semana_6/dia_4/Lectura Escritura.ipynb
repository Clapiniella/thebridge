{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![imagen](../../imagenes/python.jpg)\n",
    "\n",
    "# Lectura Escritura\n",
    "### Autor: [Daniel Ortiz López](https://www.linkedin.com/in/daniel-ortiz-l%C3%B3pez/)\n",
    "\n",
    "En este módulo vas a ver diferentes maneras de leer y escribir datos desde archivos locales. Rara vez trabajaras únicamente con los datos que genere tu programa de Python, sino que lo normal será acudir a una fuente de datos, o leer de algún archivo.\n",
    "\n",
    "1. [CSV](#1.-CSV)\n",
    "2. [Excel](#2.-Excel)\n",
    "3. [JSON](#3.-JSON)\n",
    "4. [TXT](#4.-TXT)\n",
    "5. [ZIP](#5.-ZIP)\n",
    "6. [pickle](#6.-pickle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. CSV\n",
    "***Comma Separated Values*. Es el estándar de la industria que se utiliza para leer/escribir datos en formato tabla**, en dos dimensiones. Se llaman *Comma Separeted Values* ya que todos los valores de las columnas van separados por comas, y las filas por saltos de línea. **Su extension de archivo es `.csv`**. Además, el 99% de las veces llevan la cabecera de columnas en la primera línea. Aunque no siempre se dará el caso, depende de la manera en la que se haya generado el CSV.\n",
    "\n",
    "**Es el archivo más común utilizado para guardar datos tabulares, puesto que ocupa muy poco espacio** ya que es simplemente un archivo de texto plano, con todos los datos separados por el caracter coma. Y además, sencillo de entender, los datos no van en un árbol json o xml... Si lo abrimos como texto plano, son los datos separados por coma, tal cual. \n",
    "\n",
    "Por supuesto, tenemos el otro gran protagonista en cuanto a almacenamiento de datos en formato tabla, **el Excel**. A ver, son cosas diferentes. El Excel tiene sus formatos (.xlsx, .xls), que encima son muy eficientes ya que el dato va comprimido, pero no deja de ser un software de pago para tratar los datos, mientras que **el CSV es un formato estándar que se utiliza en todos los sistemas operativos para el exportado/importado de datos**.\n",
    "\n",
    "Como decíamos al principio, los CSVs se llaman *Comma Separated Values* porque todos los valores van separados por comas... bueno, esto no es del todo cierto ya que **puede haber otro caracter que no sea la coma**, como por ejemplo el punto y coma. ¿Por qué? Simplemente porque si tenemos datos decimales, separados por comas, no vamos a saber distinguir cuando una coma es de un decimal, o es el separador de columnas.\n",
    "\n",
    "**¿Cómo podemos leer un CSV en Python?** Con Pandas! [Aquí tienes la documentación](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parámetros interesantes del `read_csv()`**\n",
    "1. `filepath_or_buffer`: ruta donde está el CSV\n",
    "2. `sep`: el separador de los datos, por defecto es coma, pero podría ser otro como veremos en ejemplos posteriores.\n",
    "3. `header`: dónde se encuentran los nombre de columnas. Por defecto es en la primera línea.\n",
    "\n",
    "Probemos a leer el CSV desde otra ruta del ordenador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una de las columnas, la podremos usar como index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos pasar el índice a una nueva columna, simplemente creamos una columna nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos resetear también el índice, y poner ahi un numérico que vaya desde el 0 al número de filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "También es posible aplicarle nombres de columnas en la lectura de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si queremos cambiar los tipos de los datos, en la propia lectura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo leer un archivo CSV que no esté separado por comas?**\n",
    "Probemos a leer un archivo CSV, que no tiene comas como delimitador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo lee todo como una única línea ya que no encuentra comas. **Se recomienda trajar con CSVs cuyo separador sea el ; así evitamos problemas por los decimales**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Podemos tener otros caracteres que separen los datos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escritura de CSV**\n",
    "\n",
    "Para escribir un CSV usamos el método `to_csv()`. Tienes [el enlace a la documentación para ver más detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"../../imagenes/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Ejercicio CSV</h3>\n",
    "\n",
    "Recupera de los ejercicios de pandas el dataframe con las poblaciones de las comunidades autónomas. En concreto, el que tiene la columna población y columna área. Crea un CSV a partir de ese DataFrame, y leelo a continuación\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Excel\n",
    "¿Qué empresa no trabaja con Excel? **Nos vamos a encontrar los formatos de datos de Excel en cualquier sitio**. Las extensiones de archivo más habituales son `.xslx` y `.xls`. Por suerte, **`pandas` tiene métodos para leer los formatos de archivo de Excel**.\n",
    "\n",
    "El problema que presenta este tipo de lectura de datos es que **no es un formato tan cerrado como el CSV**. En el CSV tenemos una estructura compacta, con todos los datos separados por comas y con una línea de cabecera en la primera fila. El Excel permite tener datos en un formato mucho más flexible, con tablas en cualquier sitio de las hojas, información en varias hojas y demás.\n",
    "\n",
    "Teniendo esto en cuenta, y sabiendo bien el formato del Excel en cuestión, podremos leerlo sin problemas con `pandas`, debido a la cantidad de argumentos que tiene la función `read_excel`. [En la documentación tienes todo el detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html).\n",
    "\n",
    "Leemos nuestro archivo de laliga, pero en este caso en Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tenemos problemas cuando los datos están perfectos, con una única hoja, y empezando en la celda A1. ¿Qué argumentos nos pueden resultar útiles?\n",
    "\n",
    "1. `io`: dónde está el archivo\n",
    "2. `sheet_name`: el nombre de la hoja\n",
    "3. `header`: dónde está la cabecera\n",
    "4. `usecols`: indica el rango de columnas Excel en el que se encuentran. Por ejemplo: 'A:F'\n",
    "5. `skiprows`: filas que deberia ignorar\n",
    "\n",
    "Veamos más ejemplos. El Excel de `laliga.xlsx` tiene varias pestañas. Por defecto, lee la primera, `Hoja1`, pero podemos especificar otras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que hay algún problema con los datos. Las primeras líneas están en blanco en el Excel. Podemos, o bien ignorarlas, o indicarle donde está la cabecera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Otro problema que nos puede surgir es que la tabla no esté ni en las primeas filas, ni en las primeras columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Escritura de Excel**\n",
    "\n",
    "Al igual que con el CSV, tenemos el método `to_excel()`, para escribir el `DataFame` en un archivo Excel. **Recuerda poner la extensión del Excel (.xlsx) en el nombre del archivo**. Tienes [el enlace a la documentación para ver más detalle](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_excel.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. JSON\n",
    "***JavaScript Objet Notation* es otro formato de texto plano que se utiliza para el itercambio de datos**. Originalmente se utilizaba como notación literal de objetos en JavaScript, pero actualmente es un formato de datos independiente del lenguaje. JavaScript es un lenguaje de programción web, por lo que JSON se utiliza mucho en el intercambio de objetos entre cliente y servidor.\n",
    "\n",
    "**¿Qué diferencia hay con un CSV o un Excel?** Ya no tenemos esa estructura de fila/columna, sino que ahora es un formato tipo clave/valor, como si fuese un diccionario. En una tabla en la fila 1, columna 1, tienes un valor. En un JSON no, en la clave \"mi_calve\" puedes tener almacenado un valor, una lista o incluso un objeto. Salimos del formato tabla al que estamos acostubrados para ganar en flexibilidad.\n",
    "\n",
    "Un JSON tiene la siguiente pinta:\n",
    "\n",
    "![imagen](../../imagenes/json_image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data =  {\n",
    "        \"firstName\": \"Jane\",\n",
    "        \"lastName\": \"Doe\",\n",
    "        \"hobbies\": [\"running\", \"sky diving\", \"singing\"],\n",
    "        \"age\": 35,\n",
    "        \"children\": [\n",
    "            {\n",
    "                \"firstName\": \"Alice\",\n",
    "                \"age\": 6\n",
    "            },\n",
    "            {\n",
    "                \"firstName\": \"Bob\",\n",
    "                \"age\": 8\n",
    "            }\n",
    "        ]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Puedo guardar el JSON en un archivo. Para ello, usamos la librería `json`**, que viene incluida en la instalación de Anaconda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O también objetos de una clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo puedo guardar en un archivo *pepe.json*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego lo puedo volver a cargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el siguiente ejemplo, utilizamos `pandas` y leeremos el archivo JSON, de tal manera que nos transforme los datos en formato tabla, en un `DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. TXT\n",
    "**Son simplemente archivos donde hay texto**. Hemos visto que los CSVs y los JSON tienen su propio formato y extension. En el caso del .txt no tienen ninguno específico aunque no quita para que sus elementos estén separados por comas, y se pueda leer igualmente como si fuese un CSV.\n",
    "\n",
    "Cuando almancenamos datos siempre tienen una estructura, por lo que aunque sea un `.txt`, llevará unos datos o bien en formato json, separados por comas, tabulaciones, puntos y comas...\n",
    "\n",
    "Por ejemplo, si tenemos los datos de la liga guardados en un `.txt`, separados por tabulaciones, lo podremos leer con el `pd.read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda que la separación por tabulaciones, también tiene su propia extensión: el `.tsv`, que igualmente lo podremos leer con `read_csv()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El método `read_csv()` no se ciñe únicamente a leer CSVs, sino a prácticamente cualquier archivo que lleve un acarácter concreto en la separación de sus campos. Si conocemos ese caracter, sabremos leer el archivo con `pandas`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ZIP\n",
    "En ocasiones los datos que recibimos en nuestros programas están compimidos, ya sea en un formato `.zip`, `.rar`, `.7z`, u otro tipo de archivo.\n",
    "\n",
    "En este apartado verás un ejemplo de cómo descomprimir archivos `.zip`. Para ello empleamos la librería `zipfile` que viene incluidad en la instalación de Anaconda. [Tienes el enlace a la documentación para más detalle](https://docs.python.org/3/library/zipfile.html#zipfile-objects).\n",
    "\n",
    "Para extraer todos los archivos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quieres descomprimir un archivo `.rar` [tendrás que descargarte un paquete coom por ejemplo `unrar`.](https://pypi.org/project/unrar/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    " <tr><td width=\"80\"><img src=\"../../imagenes/ejercicio.png\" style=\"width:auto;height:auto\"></td>\n",
    "     <td style=\"text-align:left\">\n",
    "         <h3>Ejercicio zip</h3>\n",
    "\n",
    "Consulta la documentación para extrar un único archivo, por nombre\n",
    "         \n",
    " </td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile('laligaZIP.zip', 'r') as zip_ref:\n",
    "    zip_ref.extract('laligaZIP.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. pickle\n",
    "**`pickle` es el módulo que nos permite serializar y deserializar un objeto de Pyhton**. Esta operación lo que hace es traducirlo a un stream de bytes.\n",
    "\n",
    "A efectos prácticos, lo que nos permite es guardar objetos de Python, y recuperarlos más adelante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pers1\n",
    "\n",
    "df = pd.read_csv(\"laliga.csv\")\n",
    "df.head()\n",
    "\n",
    "with open('pepe.json') as json_file:\n",
    "    data = json.load(json_file)\n",
    "    \n",
    "with open('important', \"wb\") as f:\n",
    "    pickle.dump(pers1, f)\n",
    "    pickle.dump(df, f)\n",
    "    pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('important', \"rb\") as f:\n",
    "    a = pickle.load(f)\n",
    "    b = pickle.load(f)\n",
    "    c = pickle.load(f)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
