{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zWl5iuMThonQ"
   },
   "source": [
    "# Bajando datos de diferentes fuentes. Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8fjA0nyhonR"
   },
   "source": [
    "## Bajar datos de Bicimad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4xGwVDZxhonR"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# url = 'https://opendata.emtmadrid.es/getattachment/7517a650-ccdf-4ab1-b1b0-a1d13694472e/201906_Usage_Bicimad.aspx'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "uVRFbVZrhonV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uNGffwephonX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "id": "CF9u6xluhonZ",
    "outputId": "2e4e08fe-735e-4d35-ced1-2c83fc2fc743"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n-15pM_qhond"
   },
   "source": [
    "## Importando datos desde la API de INE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "02_rQqaxhond",
    "outputId": "9c045e89-11f0-4224-f0ec-ae74f270da37"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# url_plantilla = 'http://servicios.ine.es/wstempus/js/ES/DATOS_SERIE/{codigo}?nult={num_datos}'\n",
    "\n",
    "# codigo de la serie de datos a consultar y numero de datos\n",
    "\n",
    "\n",
    "\n",
    "# realizar la descarga de los datos usando la libreria request, y leyendo el formato json\n",
    "\n",
    "\n",
    "# obtenemos el nombre de la serie para nombrar la columna en el data frame\n",
    "\n",
    "\n",
    "# Creamos una serie con las fechas, y las convertimos a zona horaria española y formateamos\n",
    "\n",
    "\n",
    "# en x la columna Fecha sale del valor en datos['Data'] pero formateando a fecha\n",
    "\n",
    "\n",
    "\n",
    "# creamos una lista con los valores de la serie que vienen en el tag 'Valor'\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MADrbCAmhong"
   },
   "outputs": [],
   "source": [
    "# contruimos un dataframe de pandas con los valores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Su7RWmOhhoni",
    "outputId": "1693d7a7-3ad5-4bbe-c599-2b84b279faca"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JpS8k_tshonl"
   },
   "source": [
    "## Web scrapping de IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "mq61vOa_honl",
    "outputId": "51d09478-3b42-4620-c0dc-9349c9ad1327"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor index in range(0, len(movies)):\\n    # Seperate movie into: \\'place\\', \\'title\\', \\'year\\'\\n    movie_string = movies[index].get_text()\\n    movie = (\\' \\'.join(movie_string.split()).replace(\\'.\\', \\'\\'))\\n    movie_title = movie[len(str(index))+1:-7]\\n    year = re.search(\\'\\\\((.*?)\\\\)\\', movie_string).group(1)\\n    place = movie[:len(str(index))-(len(movie))]\\n    data = {\"movie_title\": movie_title,\\n            \"year\": year,\\n            \"place\": place,\\n            \"star_cast\": crew[index],\\n            \"rating\": ratings[index],\\n            \"vote\": votes[index],\\n            \"link\": links[index]}\\n    imdb.append(data)\\ndf = pd.DataFrame(imdb)\\ndf\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Download IMDB's Top 250 data\n",
    "\n",
    "\n",
    "# Store each item into dictionary (data), then put those into a list (imdb)\n",
    "\n",
    "'''\n",
    "for index in range(0, len(movies)):\n",
    "    # Seperate movie into: 'place', 'title', 'year'\n",
    "    movie_string = movies[index].get_text()\n",
    "    movie = (' '.join(movie_string.split()).replace('.', ''))\n",
    "    movie_title = movie[len(str(index))+1:-7]\n",
    "    year = re.search('\\((.*?)\\)', movie_string).group(1)\n",
    "    place = movie[:len(str(index))-(len(movie))]\n",
    "    data = {\"movie_title\": movie_title,\n",
    "            \"year\": year,\n",
    "            \"place\": place,\n",
    "            \"star_cast\": crew[index],\n",
    "            \"rating\": ratings[index],\n",
    "            \"vote\": votes[index],\n",
    "            \"link\": links[index]}\n",
    "    imdb.append(data)\n",
    "df = pd.DataFrame(imdb)\n",
    "df\n",
    "'''\n",
    "\n",
    "\n",
    "#for item in imdb:\n",
    "#    print(item['place'], '-', item['movie_title'], '('+item['year']+') -', 'Starring:', item['star_cast'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoE5s2BThono"
   },
   "source": [
    "## Accediendo a datos de twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "kTUQb5vphono"
   },
   "outputs": [],
   "source": [
    "#pip install tweepy\n",
    "\n",
    "\n",
    "# estos token y keys hay que generarlos desde Twitter: https://apps.twitter.com\n",
    "# https://developer.twitter.com/\n",
    "# hay que registrarse una cuenta de desarrollador de aplicaciones que usan Twitter\n",
    "# esos token y keys caducan pasado un tiempo (nos avisa al crearlos)\n",
    "\n",
    "access_token = \"\"  \n",
    "access_token_secret = \"\"  \n",
    "consumer_key = \"\"  \n",
    "consumer_secret = \"\"  \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tkNpF4Uwhonq",
    "outputId": "b8c02159-e16f-460f-eed5-2331e3f9c204"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Use csv Writer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "UTJjfJjBhont"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Use csv Writer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnScDfXghonv"
   },
   "source": [
    "## Bajando datos de la calidad del aire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oQL_gonKhonw"
   },
   "source": [
    "También existe un dataset en Kaggle, pero vamos a ver un ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OPyVBu24honw"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# url2 = \"http://www.mambiente.munimadrid.es/opendata/horario.txt\"\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GTd8NHDLhony",
    "outputId": "bc75b9c6-cd36-4c39-ab2a-63dca3342e7a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "1-DataAccess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
